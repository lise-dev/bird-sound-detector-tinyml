# Daily Log - 05/05/2025

## Goals for the day
- [x] Read the full BirdNET paper
- [x] Understand key technical concepts: CNNs, quantization, inference
- [x] Clarify how hyperparameters affect model performance: batch size, overlap, sensitivity

## Tasks completed
- Read the entire BirdNET paper, including methodology and experimental results
- Identified and summarized the core components: CNN architecture, data pipeline, and optimization
- Learned and documented the role of:
  - Quantization (FP32, FP16, INT8)
  - Inference process (initialization, warm-up, prediction, memory use)
  - Hyperparameters (batch size, overlap, sensitivity, confidence threshold)
- Watched a video explaining CNNs in simple terms and how they apply to spectrograms

## Problems encountered
- Some terms were unclear at first (e.g., “inference”, “quantization”), needed simplification
- Understanding the trade-offs between memory usage and detection accuracy required examples

## In progress
- Deepening understanding of spectrogram features used by CNNs
- Preparing to experiment with different parameter settings in BirdNET Analyzer

## Notes / Observations
- CNNs treat spectrograms like images and learn to detect patterns related to bird calls
- Quantization is essential for deploying models on microcontrollers (INT8 ideal for embedded)
- Overlap and batch size directly impact processing time and memory usage
- Sensitivity and confidence thresholds are critical to balance false positives and missed detections
- Using data from Xeno-Canto can bias results if the model has already seen those samples

## Resources used
- BirdNET paper (full)
- YouTube: “Convolutional Neural Networks - Simply Explained”
- Notes and explanations from ChatGPT (this conversation)

## Questions / Needs
- When will the Nicla Voice device be available for embedded deployment tests?
- Should I prepare BirdNET Analyzer v2.4 INT8 version as the default baseline?
